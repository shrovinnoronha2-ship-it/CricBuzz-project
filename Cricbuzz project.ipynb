{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n",
      "\n",
      "Current CSV content:\n",
      "     0                  1              2\n",
      "0    1    ,Daryl Mitchell   ,New Zealand\n",
      "1    2       ,Virat Kohli         ,India\n",
      "2    3    ,Ibrahim Zadran   ,Afghanistan\n",
      "3    4      ,Rohit Sharma         ,India\n",
      "4    5      ,Shubman Gill         ,India\n",
      "5    6        ,Babar Azam      ,Pakistan\n",
      "6    7      ,Harry Tector       ,Ireland\n",
      "7    8         ,Shai Hope   ,West Indies\n",
      "8    9  ,Charith Asalanka     ,Sri Lanka\n",
      "9   10          ,KL Rahul         ,India\n",
      "10  11      ,Shreyas Iyer         ,India\n",
      "11  12       ,Travis Head     ,Australia\n",
      "12  13   ,Quinton de Kock  ,South Africa\n",
      "13  14   ,Pathum Nissanka     ,Sri Lanka\n",
      "14  15      ,Kusal Mendis     ,Sri Lanka\n",
      "\n",
      "First few rows:\n",
      "   0                1             2\n",
      "0  1  ,Daryl Mitchell  ,New Zealand\n",
      "1  2     ,Virat Kohli        ,India\n",
      "2  3  ,Ibrahim Zadran  ,Afghanistan\n",
      "3  4    ,Rohit Sharma        ,India\n",
      "4  5    ,Shubman Gill        ,India\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'E:\\Downloads\\batsmen_rankings.csv'\n",
    "\n",
    "# Try reading the CSV file\n",
    "try:\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    print(\"File loaded successfully!\")\n",
    "    print(\"\\nCurrent CSV content:\")\n",
    "    print(df)\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    print(\"Please check the path and file name.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame (rows, columns):\n",
      "(15, 3)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Number of columns in DataFrame:\n",
      "3\n",
      "\n",
      "==================================================\n",
      "\n",
      "First few rows as raw data:\n",
      "Row 0:\n",
      "  Column 0: 1\n",
      "  Column 1: ',Daryl Mitchell'\n",
      "  Column 2: ',New Zealand'\n",
      "Row 1:\n",
      "  Column 0: 2\n",
      "  Column 1: ',Virat Kohli'\n",
      "  Column 2: ',India'\n",
      "Row 2:\n",
      "  Column 0: 3\n",
      "  Column 1: ',Ibrahim Zadran'\n",
      "  Column 2: ',Afghanistan'\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the DataFrame (rows, columns):\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Number of columns in DataFrame:\")\n",
    "print(len(df.columns))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"First few rows as raw data:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"Row {i}:\")\n",
    "    for col in range(len(df.columns)):\n",
    "        print(f\"  Column {col}: {repr(df.iloc[i, col])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "   Rank            Name      Country\n",
      "0     1  Daryl Mitchell  New Zealand\n",
      "1     2     Virat Kohli        India\n",
      "2     3  Ibrahim Zadran  Afghanistan\n",
      "3     4    Rohit Sharma        India\n",
      "4     5    Shubman Gill        India\n",
      "\n",
      "==================================================\n",
      "\n",
      "Data types:\n",
      "Rank        int64\n",
      "Name       object\n",
      "Country    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to work with\n",
    "df_clean = df.copy()\n",
    "\n",
    "df_clean[1] = df_clean[1].str.lstrip(',').str.strip()\n",
    "\n",
    "df_clean[2] = df_clean[2].str.lstrip(',').str.strip()\n",
    "\n",
    "# Assign proper column names\n",
    "df_clean.columns = ['Rank', 'Name', 'Country']\n",
    "\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_clean.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Data types:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tab characters found in the DataFrame.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Final cleaned DataFrame preview:\n",
      "   Rank            Name      Country\n",
      "0     1  Daryl Mitchell  New Zealand\n",
      "1     2     Virat Kohli        India\n",
      "2     3  Ibrahim Zadran  Afghanistan\n",
      "3     4    Rohit Sharma        India\n",
      "4     5    Shubman Gill        India\n"
     ]
    }
   ],
   "source": [
    "# Check for tab characters in the entire DataFrame\n",
    "has_tabs = df_clean.applymap(lambda x: isinstance(x, str) and '\\t' in x).any().any()\n",
    "\n",
    "if has_tabs:\n",
    "    print(\"Tab characters found in the DataFrame. Removing them...\")\n",
    "    # Remove tabs from all string columns\n",
    "    df_clean = df_clean.applymap(lambda x: x.replace('\\t', '') if isinstance(x, str) else x)\n",
    "else:\n",
    "    print(\"No tab characters found in the DataFrame.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Final cleaned DataFrame preview:\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: E:\\Downloads\\batsmen_rankings_cleaned.csv\n",
      "\n",
      "==================================================\n",
      "\n",
      "Verification - First 5 rows of saved file:\n",
      "   Rank            Name      Country\n",
      "0     1  Daryl Mitchell  New Zealand\n",
      "1     2     Virat Kohli        India\n",
      "2     3  Ibrahim Zadran  Afghanistan\n",
      "3     4    Rohit Sharma        India\n",
      "4     5    Shubman Gill        India\n"
     ]
    }
   ],
   "source": [
    "# Define the path for the cleaned file\n",
    "cleaned_file_path = r'E:\\Downloads\\batsmen_rankings_cleaned.csv'\n",
    "\n",
    "\n",
    "df_clean.to_csv(cleaned_file_path, index=False) # Save to CSV\n",
    "\n",
    "print(f\"Cleaned data saved to: {cleaned_file_path}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "df_verify = pd.read_csv(cleaned_file_path) # Verify the saved file by reading it back\n",
    "print(\"Verification - First 5 rows of saved file:\")\n",
    "print(df_verify.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL (newline-delimited JSON) saved to: E:\\Downloads\\batsmen_rankings_cleaned.jsonl\n",
      "\n",
      "==================================================\n",
      "\n",
      "First 3 lines of JSONL file:\n",
      "Line 1: {\"Rank\":1,\"Name\":\"Daryl Mitchell\",\"Country\":\"New Zealand\"}\n",
      "Line 2: {\"Rank\":2,\"Name\":\"Virat Kohli\",\"Country\":\"India\"}\n",
      "Line 3: {\"Rank\":3,\"Name\":\"Ibrahim Zadran\",\"Country\":\"Afghanistan\"}\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_path = r'E:\\Downloads\\batsmen_rankings_cleaned.jsonl'\n",
    "\n",
    "with open(jsonl_file_path, 'w') as f:\n",
    "    for _, row in df_clean.iterrows():\n",
    "       \n",
    "        f.write(row.to_json() + '\\n')\n",
    "\n",
    "print(f\"JSONL (newline-delimited JSON) saved to: {jsonl_file_path}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"First 3 lines of JSONL file:\") # Displaying first 3 lines to verify format\n",
    "with open(jsonl_file_path, 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()[:3]):\n",
    "        print(f\"Line {i+1}: {line.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDF file created: udf.js\n",
      "\n",
      "==================================================\n",
      "\n",
      "UDF content preview:\n",
      "\n",
      "/**\n",
      " * UDF function to transform data for BigQuery.\n",
      " * Each line is a JSON object from the JSONL file.\n",
      " */\n",
      "function transform(line) {\n",
      "    try {\n",
      "        // Parse the JSON line\n",
      "        var obj = JSON.parse(line);\n",
      "        \n",
      "        // You can transform or validate the data here\n",
      "        // Example transformations:\n",
      "        \n",
      "        // 1. Convert Rank to integer (if not already)\n",
      "        if (obj.Rank) {\n",
      "            obj.Rank = parseInt(obj.Rank);\n",
      "        }\n",
      "        \n",
      "        // 2. Ensure Name and Country ...\n"
     ]
    }
   ],
   "source": [
    "udf_content = \"\"\"\n",
    "/**\n",
    " * UDF function to transform data for BigQuery.\n",
    " * Each line is a JSON object from the JSONL file.\n",
    " */\n",
    "function transform(line) {\n",
    "    try {\n",
    "        // Parse the JSON line\n",
    "        var obj = JSON.parse(line);\n",
    "        \n",
    "        // You can transform or validate the data here\n",
    "        // Example transformations:\n",
    "        \n",
    "        // 1. Convert Rank to integer (if not already)\n",
    "        if (obj.Rank) {\n",
    "            obj.Rank = parseInt(obj.Rank);\n",
    "        }\n",
    "        \n",
    "        // 2. Ensure Name and Country are strings and trim whitespace\n",
    "        if (obj.Name) {\n",
    "            obj.Name = obj.Name.toString().trim();\n",
    "        }\n",
    "        \n",
    "        if (obj.Country) {\n",
    "            obj.Country = obj.Country.toString().trim();\n",
    "        }\n",
    "        \n",
    "        // 3. Add a processing timestamp (optional)\n",
    "        obj.processed_timestamp = new Date().toISOString();\n",
    "        \n",
    "        // Return as JSON string\n",
    "        return JSON.stringify(obj);\n",
    "        \n",
    "    } catch (e) {\n",
    "        // Log error and return null to skip this record\n",
    "        console.error(\"Error processing line:\", e);\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open('udf.js', 'w') as f:\n",
    "    f.write(udf_content)\n",
    "\n",
    "print(\"UDF file created: udf.js\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"UDF content preview:\")\n",
    "print(udf_content[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bq.json file not found locally\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "try:\n",
    "    with open('bq.json', 'r') as f:\n",
    "        content = f.read()\n",
    "        print(\"Current bq.json content:\")\n",
    "        print(repr(content))  # Show raw content with special characters\n",
    "        print(\"\\nLength:\", len(content))\n",
    "        \n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "            print(\"\\n‚úÖ Valid JSON structure\")\n",
    "            print(json.dumps(parsed, indent=2))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"\\n‚ùå Invalid JSON: {e}\")\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(\"bq.json file not found locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema file created: bq.json\n",
      "\n",
      "============================================================\n",
      "\n",
      "File content (first 200 chars):\n",
      "'{\\n  \"BigQuery Schema\": [\\n    {\\n      \"name\": \"Rank\",\\n      \"type\": \"INTEGER\"\\n    },\\n    {\\n      \"name\": \"Name\",\\n      \"type\": \"STRING\"\\n    },\\n    {\\n      \"name\": \"Country\",\\n      \"type\": \"STRING\"\\n    '\n",
      "\n",
      "Full content:\n",
      "{\n",
      "  \"BigQuery Schema\": [\n",
      "    {\n",
      "      \"name\": \"Rank\",\n",
      "      \"type\": \"INTEGER\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Name\",\n",
      "      \"type\": \"STRING\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Country\",\n",
      "      \"type\": \"STRING\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"processed_timestamp\",\n",
      "      \"type\": \"TIMESTAMP\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "‚úÖ Valid JSON structure\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create the correct schema format based on the template example\n",
    "schema = {\n",
    "    \"BigQuery Schema\": [\n",
    "        {\n",
    "            \"name\": \"Rank\", \n",
    "            \"type\": \"INTEGER\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Name\", \n",
    "            \"type\": \"STRING\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Country\", \n",
    "            \"type\": \"STRING\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"processed_timestamp\",\n",
    "            \"type\": \"TIMESTAMP\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('bq.json', 'w') as f:\n",
    "    json.dump(schema, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Schema file created: bq.json\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "with open('bq.json', 'r') as f:\n",
    "    content = f.read()\n",
    "    print(\"File content (first 200 chars):\")\n",
    "    print(repr(content[:200]))\n",
    "    print(\"\\nFull content:\")\n",
    "    print(content)\n",
    "\n",
    "try:\n",
    "    with open('bq.json', 'r') as f:\n",
    "        parsed = json.load(f)\n",
    "    print(\"\\n‚úÖ Valid JSON structure\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\n‚ùå Invalid JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Current Working Directory:\n",
      "   C:\\Users\\HP1\\Desktop\\sem2\\Class Test II\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìç Full Path of bq.json:\n",
      "   C:\\Users\\HP1\\Desktop\\sem2\\Class Test II\\bq.json\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìÇ Files in current directory:\n",
      "   ‚úÖ bq.json - 302 bytes - Location: C:\\Users\\HP1\\Desktop\\sem2\\Class Test II\\bq.json\n",
      "   ‚úÖ Diabetes.csv - 18966 bytes - Location: C:\\Users\\HP1\\Desktop\\sem2\\Class Test II\\Diabetes.csv\n",
      "   ‚úÖ illinois_vote_2016.csv - 9578 bytes - Location: C:\\Users\\HP1\\Desktop\\sem2\\Class Test II\\illinois_vote_2016.csv\n",
      "   ‚úÖ udf.js - 1123 bytes - Location: C:\\Users\\HP1\\Desktop\\sem2\\Class Test II\\udf.js\n",
      "\n",
      "============================================================\n",
      "\n",
      "üí° To upload to Google Cloud Storage, use:\n",
      "   gsutil cp bq.json gs://bkt-dataflo-metadata/\n",
      "\n",
      "   Or using Python code:\n",
      "   from google.cloud import storage\n",
      "   client = storage.Client()\n",
      "   bucket = client.get_bucket('bkt-dataflo-metadata')\n",
      "   blob = bucket.blob('bq.json')\n",
      "   blob.upload_from_filename('bq.json')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "bq_json_path = os.path.join(current_directory, 'bq.json')\n",
    "\n",
    "print(\"üìÅ Current Working Directory:\")\n",
    "print(f\"   {current_directory}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"üìç Full Path of bq.json:\")\n",
    "print(f\"   {bq_json_path}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check all files in current directory\n",
    "print(\"üìÇ Files in current directory:\")\n",
    "files = os.listdir(current_directory)\n",
    "for file in files:\n",
    "    if file.endswith(('.json', '.jsonl', '.js', '.csv')):\n",
    "        full_path = os.path.join(current_directory, file)\n",
    "        size = os.path.getsize(full_path)\n",
    "        print(f\"   ‚úÖ {file} - {size} bytes - Location: {full_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"üí° To upload to Google Cloud Storage, use:\")\n",
    "print(\"   gsutil cp bq.json gs://bkt-dataflo-metadata/\")\n",
    "print(\"\\n   Or using Python code:\")\n",
    "print(\"   from google.cloud import storage\")\n",
    "print(\"   client = storage.Client()\")\n",
    "print(\"   bucket = client.get_bucket('bkt-dataflo-metadata')\")\n",
    "print(\"   blob = bucket.blob('bq.json')\")\n",
    "print(\"   blob.upload_from_filename('bq.json')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema file created at: E:\\Downloads\\bq.json\n",
      "\n",
      "============================================================\n",
      "\n",
      "File exists: E:\\Downloads\\bq.json\n",
      "File size: 302 bytes\n",
      "\n",
      "File content preview:\n",
      "{\n",
      "  \"BigQuery Schema\": [\n",
      "    {\n",
      "      \"name\": \"Rank\",\n",
      "      \"type\": \"INTEGER\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Name\",\n",
      "      \"type\": \"STRING\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Country\",\n",
      "      \"type\": \"STRING\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"processed_timestamp\",\n",
      "      \"type\": \"TIMESTAMP\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "target_dir = r\"E:\\Downloads\"\n",
    "\n",
    "# Create the schema\n",
    "schema = {\n",
    "    \"BigQuery Schema\": [\n",
    "        {\n",
    "            \"name\": \"Rank\", \n",
    "            \"type\": \"INTEGER\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Name\", \n",
    "            \"type\": \"STRING\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Country\", \n",
    "            \"type\": \"STRING\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"processed_timestamp\",\n",
    "            \"type\": \"TIMESTAMP\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "bq_json_path = os.path.join(target_dir, \"bq.json\")\n",
    "\n",
    "with open(bq_json_path, 'w') as f:\n",
    "    json.dump(schema, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Schema file created at: {bq_json_path}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "if os.path.exists(bq_json_path):\n",
    "    file_size = os.path.getsize(bq_json_path)\n",
    "    print(f\"File exists: {bq_json_path}\")\n",
    "    print(f\"File size: {file_size} bytes\")\n",
    "    \n",
    "    with open(bq_json_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        print(\"\\nFile content preview:\")\n",
    "        print(content[:300] + \"...\" if len(content) > 300 else content)\n",
    "else:\n",
    "    print(\"‚ùå File was not created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
